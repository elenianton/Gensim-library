{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TASK1_gensim.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7tdWTP8TGW9"
      },
      "source": [
        "**TASK 1**\n",
        "\n",
        "*Deep Learning*\n",
        "\n",
        "~~\n",
        "\n",
        " \n",
        "**Ονοματεπώνυμο**: Αντωνακάκη Ελένη\n",
        "\n",
        "**ΑΜ**: Lt1200002"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlFu_ImsOqd3"
      },
      "source": [
        "#import all the necessary libraries\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import random\n",
        "import gensim\n",
        "import time\n",
        "import numpy as np\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VGD6PqhO0KV"
      },
      "source": [
        "#define the path as \"corpus_path\"\n",
        "corpus_path = os.path.abspath(\"europarl-v7.el-en.en\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5ReOW-uYx_R"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "> Επεξεργασία του dataset *Europarl-v7.el-en.en*\n",
        "\n",
        "\n",
        "\n",
        "          - Διαγραφή σημείων στίξης.\n",
        "          - Μετατροπή χαρακτήρων σε πεζά γράμματα.\n",
        "          - Διαγραφή αριθμών.\n",
        "          - Διαγραφή λέξεων με υψηλή συχνότητα (stopwords).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnlj4mlRO0Q4",
        "outputId": "b1d2c092-d21a-4985-fffd-55de238c3112"
      },
      "source": [
        "lines_list=[]\n",
        "\n",
        "with open(corpus_path, 'r', encoding='utf-8') as f:\n",
        "    lines=f.read()\n",
        "    content_list = lines. split(\"\\n\")\n",
        "    random.seed(2020)\n",
        "    sampling = random.choices(content_list, k=100000)      # Choices with repetition, k= number of sentences\n",
        "    for sampl in sampling:\n",
        "        #print(sampl) \n",
        "        sampl = re.sub(r'[^\\w\\s]', '', sampl) #remove punctuation\n",
        "        sampl = re.sub('[\\W]+', ' ', sampl.lower()) # Convert all words to lowercase\n",
        "        sampl = re.sub(r'\\d+', '', sampl) # Remove numbers\n",
        "        sampl= remove_stopwords(sampl) #remove stopwords with gensim \n",
        "        sampl= sampl.split()\n",
        "      \n",
        "        lines_list.append(sampl)\n",
        "    \n",
        "print(lines_list[8])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pl', 'mr', 'president', 'forthcoming', 'european', 'council', 'summit', 'certain', 'extent', 'mark', 'official', 'start', 'german', 'presidency']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB29D8e4hJvg"
      },
      "source": [
        "\n",
        "\n",
        "> Δημιουργία μοντέλου \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaTkhw7-O0Vf"
      },
      "source": [
        "import logging\n",
        "\n",
        "# Enable logging at the `INFO` level and set a custom format--the\n",
        "# default log format is pretty wordy. \n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s : %(message)s', # Display just time and message.\n",
        "    datefmt='%H:%M:%S', # Display time, but not the date.\n",
        "    level=logging.INFO)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-40u02RMO0Yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a681c1-64ab-4ddd-af5d-c50bd8f47240"
      },
      "source": [
        "model = gensim.models.Word2Vec (    \n",
        "    size=100,    # Number of features in word vector\n",
        "    \n",
        "    window=10,   # Context window size (in each direction)\n",
        "                 #   Default is 5\n",
        "    \n",
        "    min_count=2, # Words must appear this many times to be in vocab.\n",
        "                 #   Default is 5\n",
        "    \n",
        "    workers=10,  # Training thread count\n",
        "    \n",
        "    sg=0,        # 0: CBOW, 1: Skip-gram. \n",
        "                 #   Default is 0, CBOW\n",
        "    \n",
        "    hs=0,        # 0: Negative Sampling, 1: Hierarchical Softmax\n",
        "                 #   Default is 0, NS\n",
        "    \n",
        "    negative=5   # Nmber of negative samples \n",
        "                 #   Default is 5\n",
        ")\n",
        "\n",
        "print(\"Parameters are defined!!\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters are defined!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsnxgum6hqjS"
      },
      "source": [
        "\n",
        "\n",
        "> Δημιουργία λεξιλογίου και training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO4CduWvO0by",
        "outputId": "b965e9e7-59d0-40b6-87cc-44d86943d9aa"
      },
      "source": [
        "model.build_vocab(lines_list, progress_per=20000)\n",
        "\n",
        "#test the shape of a vector\n",
        "test_shape_vec= model.wv.get_vector('men').shape \n",
        "print(test_shape_vec)\n",
        "\n",
        " # Get numpy vector of a word (just for a trial)\n",
        "vector = model['men'] #vector size = 100\n",
        "print(vector)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09:41:16 : collecting all words and their counts\n",
            "09:41:16 : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "09:41:16 : PROGRESS: at sentence #20000, processed 229524 words, keeping 16938 word types\n",
            "09:41:16 : PROGRESS: at sentence #40000, processed 457867 words, keeping 22412 word types\n",
            "09:41:16 : PROGRESS: at sentence #60000, processed 687464 words, keeping 26008 word types\n",
            "09:41:16 : PROGRESS: at sentence #80000, processed 916157 words, keeping 28978 word types\n",
            "09:41:16 : collected 31306 word types from a corpus of 1144465 raw words and 100000 sentences\n",
            "09:41:16 : Loading a fresh vocabulary\n",
            "09:41:16 : effective_min_count=2 retains 20585 unique words (65% of original 31306, drops 10721)\n",
            "09:41:16 : effective_min_count=2 leaves 1133744 word corpus (99% of original 1144465, drops 10721)\n",
            "09:41:16 : deleting the raw counts dictionary of 31306 items\n",
            "09:41:16 : sample=0.001 downsamples 23 most-common words\n",
            "09:41:16 : downsampling leaves estimated 1089265 word corpus (96.1% of prior 1133744)\n",
            "09:41:16 : estimated required memory for 20585 words and 100 dimensions: 26760500 bytes\n",
            "09:41:16 : resetting layer weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n",
            "[-6.49521418e-04 -3.31129530e-03  3.21102631e-03 -2.96769338e-03\n",
            " -3.20525817e-03 -3.02590174e-03  1.45736302e-03  3.50894686e-03\n",
            "  1.96280819e-03 -2.40616431e-03 -4.01764177e-03 -4.82512172e-03\n",
            "  3.86702223e-03 -1.68787828e-03  3.98632232e-03 -2.50032847e-03\n",
            " -3.03497212e-03 -2.80117569e-03 -1.08691526e-03 -2.84832134e-03\n",
            "  1.17631233e-03 -7.74480759e-06  1.08415967e-04 -3.29801976e-03\n",
            "  3.55493743e-03  2.37765536e-03 -6.16915873e-04  4.60495381e-03\n",
            " -9.82209109e-04 -4.88782767e-03 -2.08972394e-03  2.53543770e-03\n",
            "  3.60812736e-03 -3.86094511e-03 -2.32960912e-03  3.54936882e-03\n",
            " -2.02417630e-03 -4.66270000e-03  3.29522649e-03 -4.53021144e-03\n",
            "  4.12711015e-05  2.69122282e-03 -3.99221387e-03  4.52329265e-03\n",
            "  1.13637222e-03  3.09676398e-03  1.84786343e-03  4.34815511e-03\n",
            " -3.29718972e-03  3.22475564e-03  4.30945103e-04 -1.04851951e-03\n",
            "  3.75577575e-03 -2.27013981e-04 -3.12018185e-03  1.77147507e-03\n",
            "  2.54957844e-03  3.58024146e-03 -1.15943898e-04 -4.28863009e-03\n",
            "  3.36555205e-03 -1.37452991e-03 -2.50285841e-03  1.18080396e-04\n",
            " -2.99218274e-03 -2.60584243e-03  2.32208101e-03  1.37592503e-03\n",
            "  1.58933981e-03  1.44083030e-03  9.66781110e-04  1.41938194e-03\n",
            "  1.47870043e-04 -2.34029954e-03 -4.97157453e-03 -4.57123097e-04\n",
            "  5.43897448e-04  2.10198457e-03  4.29568812e-03 -4.23150370e-03\n",
            " -2.58629140e-03  1.21877925e-03  2.53565144e-03  1.90230890e-03\n",
            " -1.36040733e-03  3.72897880e-03  1.25059730e-03 -2.82461569e-03\n",
            " -2.53619137e-03 -4.55987640e-03  2.10519764e-03  3.16505390e-03\n",
            "  4.52209031e-03  2.44970270e-03  2.16676318e-03  1.61756075e-03\n",
            " -4.45153052e-03  4.03414341e-03  3.30083794e-03  4.31843987e-03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4rnXWNLO0fH",
        "outputId": "ab227be6-9708-4970-bf1a-0bf6b836ab95"
      },
      "source": [
        "print('Training the model...')\n",
        "\n",
        "model.train(\n",
        "    lines_list,\n",
        "    total_examples=len(lines_list),\n",
        "    epochs=10,        \n",
        "    report_delay=10.0 \n",
        ")\n",
        "\n",
        "print('  Done.')\n",
        "print('')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09:41:21 : training model with 10 workers on 20585 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09:41:22 : EPOCH 1 - PROGRESS: at 38.44% examples, 411961 words/s, in_qsize 14, out_qsize 5\n",
            "09:41:23 : worker thread finished; awaiting finish of 9 more threads\n",
            "09:41:23 : worker thread finished; awaiting finish of 8 more threads\n",
            "09:41:23 : worker thread finished; awaiting finish of 7 more threads\n",
            "09:41:23 : worker thread finished; awaiting finish of 6 more threads\n",
            "09:41:23 : worker thread finished; awaiting finish of 5 more threads\n",
            "09:41:23 : worker thread finished; awaiting finish of 4 more threads\n",
            "09:41:23 : worker thread finished; awaiting finish of 3 more threads\n",
            "09:41:23 : worker thread finished; awaiting finish of 2 more threads\n",
            "09:41:23 : worker thread finished; awaiting finish of 1 more threads\n",
            "09:41:23 : worker thread finished; awaiting finish of 0 more threads\n",
            "09:41:23 : EPOCH - 1 : training on 1144465 raw words (1089342 effective words) took 2.1s, 519275 effective words/s\n",
            "09:41:24 : EPOCH 2 - PROGRESS: at 38.45% examples, 416513 words/s, in_qsize 13, out_qsize 6\n",
            "09:41:25 : worker thread finished; awaiting finish of 9 more threads\n",
            "09:41:25 : worker thread finished; awaiting finish of 8 more threads\n",
            "09:41:25 : worker thread finished; awaiting finish of 7 more threads\n",
            "09:41:25 : worker thread finished; awaiting finish of 6 more threads\n",
            "09:41:25 : worker thread finished; awaiting finish of 5 more threads\n",
            "09:41:25 : worker thread finished; awaiting finish of 4 more threads\n",
            "09:41:25 : worker thread finished; awaiting finish of 3 more threads\n",
            "09:41:25 : worker thread finished; awaiting finish of 2 more threads\n",
            "09:41:25 : worker thread finished; awaiting finish of 1 more threads\n",
            "09:41:25 : worker thread finished; awaiting finish of 0 more threads\n",
            "09:41:25 : EPOCH - 2 : training on 1144465 raw words (1089128 effective words) took 2.1s, 517763 effective words/s\n",
            "09:41:27 : EPOCH 3 - PROGRESS: at 47.06% examples, 474814 words/s, in_qsize 18, out_qsize 1\n",
            "09:41:27 : worker thread finished; awaiting finish of 9 more threads\n",
            "09:41:27 : worker thread finished; awaiting finish of 8 more threads\n",
            "09:41:28 : worker thread finished; awaiting finish of 7 more threads\n",
            "09:41:28 : worker thread finished; awaiting finish of 6 more threads\n",
            "09:41:28 : worker thread finished; awaiting finish of 5 more threads\n",
            "09:41:28 : worker thread finished; awaiting finish of 4 more threads\n",
            "09:41:28 : worker thread finished; awaiting finish of 3 more threads\n",
            "09:41:28 : worker thread finished; awaiting finish of 2 more threads\n",
            "09:41:28 : worker thread finished; awaiting finish of 1 more threads\n",
            "09:41:28 : worker thread finished; awaiting finish of 0 more threads\n",
            "09:41:28 : EPOCH - 3 : training on 1144465 raw words (1089460 effective words) took 2.1s, 524226 effective words/s\n",
            "09:41:29 : EPOCH 4 - PROGRESS: at 41.06% examples, 437614 words/s, in_qsize 13, out_qsize 6\n",
            "09:41:30 : worker thread finished; awaiting finish of 9 more threads\n",
            "09:41:30 : worker thread finished; awaiting finish of 8 more threads\n",
            "09:41:30 : worker thread finished; awaiting finish of 7 more threads\n",
            "09:41:30 : worker thread finished; awaiting finish of 6 more threads\n",
            "09:41:30 : worker thread finished; awaiting finish of 5 more threads\n",
            "09:41:30 : worker thread finished; awaiting finish of 4 more threads\n",
            "09:41:30 : worker thread finished; awaiting finish of 3 more threads\n",
            "09:41:30 : worker thread finished; awaiting finish of 2 more threads\n",
            "09:41:30 : worker thread finished; awaiting finish of 1 more threads\n",
            "09:41:30 : worker thread finished; awaiting finish of 0 more threads\n",
            "09:41:30 : EPOCH - 4 : training on 1144465 raw words (1089251 effective words) took 2.1s, 525006 effective words/s\n",
            "09:41:31 : EPOCH 5 - PROGRESS: at 41.92% examples, 451095 words/s, in_qsize 17, out_qsize 1\n",
            "09:41:32 : worker thread finished; awaiting finish of 9 more threads\n",
            "09:41:32 : worker thread finished; awaiting finish of 8 more threads\n",
            "09:41:32 : worker thread finished; awaiting finish of 7 more threads\n",
            "09:41:32 : worker thread finished; awaiting finish of 6 more threads\n",
            "09:41:32 : worker thread finished; awaiting finish of 5 more threads\n",
            "09:41:32 : worker thread finished; awaiting finish of 4 more threads\n",
            "09:41:32 : worker thread finished; awaiting finish of 3 more threads\n",
            "09:41:32 : worker thread finished; awaiting finish of 2 more threads\n",
            "09:41:32 : worker thread finished; awaiting finish of 1 more threads\n",
            "09:41:32 : worker thread finished; awaiting finish of 0 more threads\n",
            "09:41:32 : EPOCH - 5 : training on 1144465 raw words (1089465 effective words) took 2.1s, 519618 effective words/s\n",
            "09:41:33 : EPOCH 6 - PROGRESS: at 45.33% examples, 489173 words/s, in_qsize 18, out_qsize 2\n",
            "09:41:34 : worker thread finished; awaiting finish of 9 more threads\n",
            "09:41:34 : worker thread finished; awaiting finish of 8 more threads\n",
            "09:41:34 : worker thread finished; awaiting finish of 7 more threads\n",
            "09:41:34 : worker thread finished; awaiting finish of 6 more threads\n",
            "09:41:34 : worker thread finished; awaiting finish of 5 more threads\n",
            "09:41:34 : worker thread finished; awaiting finish of 4 more threads\n",
            "09:41:34 : worker thread finished; awaiting finish of 3 more threads\n",
            "09:41:34 : worker thread finished; awaiting finish of 2 more threads\n",
            "09:41:34 : worker thread finished; awaiting finish of 1 more threads\n",
            "09:41:34 : worker thread finished; awaiting finish of 0 more threads\n",
            "09:41:34 : EPOCH - 6 : training on 1144465 raw words (1089039 effective words) took 2.1s, 513977 effective words/s\n",
            "09:41:35 : EPOCH 7 - PROGRESS: at 46.20% examples, 502634 words/s, in_qsize 18, out_qsize 0\n",
            "09:41:36 : worker thread finished; awaiting finish of 9 more threads\n",
            "09:41:36 : worker thread finished; awaiting finish of 8 more threads\n",
            "09:41:36 : worker thread finished; awaiting finish of 7 more threads\n",
            "09:41:36 : worker thread finished; awaiting finish of 6 more threads\n",
            "09:41:36 : worker thread finished; awaiting finish of 5 more threads\n",
            "09:41:36 : worker thread finished; awaiting finish of 4 more threads\n",
            "09:41:36 : worker thread finished; awaiting finish of 3 more threads\n",
            "09:41:36 : worker thread finished; awaiting finish of 2 more threads\n",
            "09:41:36 : worker thread finished; awaiting finish of 1 more threads\n",
            "09:41:36 : worker thread finished; awaiting finish of 0 more threads\n",
            "09:41:36 : EPOCH - 7 : training on 1144465 raw words (1089349 effective words) took 2.1s, 517469 effective words/s\n",
            "09:41:37 : EPOCH 8 - PROGRESS: at 46.20% examples, 489222 words/s, in_qsize 20, out_qsize 0\n",
            "09:41:38 : worker thread finished; awaiting finish of 9 more threads\n",
            "09:41:38 : worker thread finished; awaiting finish of 8 more threads\n",
            "09:41:38 : worker thread finished; awaiting finish of 7 more threads\n",
            "09:41:38 : worker thread finished; awaiting finish of 6 more threads\n",
            "09:41:38 : worker thread finished; awaiting finish of 5 more threads\n",
            "09:41:38 : worker thread finished; awaiting finish of 4 more threads\n",
            "09:41:38 : worker thread finished; awaiting finish of 3 more threads\n",
            "09:41:38 : worker thread finished; awaiting finish of 2 more threads\n",
            "09:41:38 : worker thread finished; awaiting finish of 1 more threads\n",
            "09:41:38 : worker thread finished; awaiting finish of 0 more threads\n",
            "09:41:38 : EPOCH - 8 : training on 1144465 raw words (1089469 effective words) took 2.1s, 513377 effective words/s\n",
            "09:41:39 : EPOCH 9 - PROGRESS: at 47.05% examples, 487069 words/s, in_qsize 19, out_qsize 1\n",
            "09:41:40 : worker thread finished; awaiting finish of 9 more threads\n",
            "09:41:40 : worker thread finished; awaiting finish of 8 more threads\n",
            "09:41:40 : worker thread finished; awaiting finish of 7 more threads\n",
            "09:41:40 : worker thread finished; awaiting finish of 6 more threads\n",
            "09:41:40 : worker thread finished; awaiting finish of 5 more threads\n",
            "09:41:40 : worker thread finished; awaiting finish of 4 more threads\n",
            "09:41:40 : worker thread finished; awaiting finish of 3 more threads\n",
            "09:41:40 : worker thread finished; awaiting finish of 2 more threads\n",
            "09:41:40 : worker thread finished; awaiting finish of 1 more threads\n",
            "09:41:40 : worker thread finished; awaiting finish of 0 more threads\n",
            "09:41:40 : EPOCH - 9 : training on 1144465 raw words (1088793 effective words) took 2.1s, 522581 effective words/s\n",
            "09:41:41 : EPOCH 10 - PROGRESS: at 46.18% examples, 492151 words/s, in_qsize 19, out_qsize 0\n",
            "09:41:42 : worker thread finished; awaiting finish of 9 more threads\n",
            "09:41:42 : worker thread finished; awaiting finish of 8 more threads\n",
            "09:41:42 : worker thread finished; awaiting finish of 7 more threads\n",
            "09:41:42 : worker thread finished; awaiting finish of 6 more threads\n",
            "09:41:42 : worker thread finished; awaiting finish of 5 more threads\n",
            "09:41:42 : worker thread finished; awaiting finish of 4 more threads\n",
            "09:41:42 : worker thread finished; awaiting finish of 3 more threads\n",
            "09:41:42 : worker thread finished; awaiting finish of 2 more threads\n",
            "09:41:42 : worker thread finished; awaiting finish of 1 more threads\n",
            "09:41:42 : worker thread finished; awaiting finish of 0 more threads\n",
            "09:41:42 : EPOCH - 10 : training on 1144465 raw words (1089274 effective words) took 2.1s, 517957 effective words/s\n",
            "09:41:42 : training on a 11444650 raw words (10892570 effective words) took 21.2s, 514596 effective words/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Done.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6XvxAaGkn4U"
      },
      "source": [
        "\n",
        "\n",
        "> Ανάλυση του dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUcwM4hxcy3G",
        "outputId": "9f38a415-cf6e-4159-e9b2-fdceae1ceda9"
      },
      "source": [
        "#find the 1o most similar words based on the Euclidean distance. Type the word in console.\n",
        "print(\"The 10 most similar words: \", model.wv.most_similar(input('Word:'))) "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word:mr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09:41:51 : precomputing L2-norms of word weight vectors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 10 most similar words:  [('madam', 0.7998259663581848), ('manuel', 0.7620275020599365), ('josé', 0.7320352792739868), ('fontaine', 0.7278258800506592), ('colleague', 0.7149097919464111), ('sl', 0.7045477628707886), ('elmar', 0.7007681131362915), ('es', 0.6847256422042847), ('mrs', 0.6640957593917847), ('barroso', 0.6554150581359863)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAVe7TNMczAb",
        "outputId": "4f1a4647-5589-4413-ce5e-c9ea86fd0dee"
      },
      "source": [
        "#similarity between two words. Type words in console.\n",
        "print(model.wv.similarity(input('Word 1: '), input('Word 2: '))) "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 1: mr\n",
            "Word 2: ms\n",
            "0.65466017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rhhly-_ubEr",
        "outputId": "b94c12b5-aabd-4464-c56d-6a79cb55093d"
      },
      "source": [
        "#print negative similarity. Type the word in console.\n",
        "\n",
        "print(model.most_similar(negative=input('Words: '),topn=1))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words: mr\n",
            "[('garnered', 0.4614514112472534)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1bd3SmzczDp",
        "outputId": "1f1a3f80-23bc-4409-dbdc-26d581192de9"
      },
      "source": [
        "#number of unique words in dataset\n",
        "vocab = list(model.wv.vocab.keys())\n",
        "\n",
        "print(\"Unique words in my dataset:\", len(vocab))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words in my dataset: 20585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "kV48d_EFfgft",
        "outputId": "ddac9eda-e2d7-4e50-f4b7-bfd0bf855d1b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sort the word list by frequency.\n",
        "words = sorted(model.wv.index2word, key=lambda word: model.wv.vocab[word].count, reverse=True)\n",
        "\n",
        "top_words = []\n",
        "for i in range(10):\n",
        "    # Add the word and it's count (formatted with commas)\n",
        "    top_words.append((words[i], '{:,}'.format(model.wv.vocab[words[i]].count)))\n",
        "\n",
        "df = pd.DataFrame(top_words, columns=['Word', 'Counts'])\n",
        "\n",
        "display(df)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>european</td>\n",
              "      <td>15,090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mr</td>\n",
              "      <td>10,265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>commission</td>\n",
              "      <td>7,846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>president</td>\n",
              "      <td>7,471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>member</td>\n",
              "      <td>6,193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>report</td>\n",
              "      <td>6,118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>states</td>\n",
              "      <td>6,102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>union</td>\n",
              "      <td>5,901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>parliament</td>\n",
              "      <td>5,693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>like</td>\n",
              "      <td>5,545</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Word  Counts\n",
              "0    european  15,090\n",
              "1          mr  10,265\n",
              "2  commission   7,846\n",
              "3   president   7,471\n",
              "4      member   6,193\n",
              "5      report   6,118\n",
              "6      states   6,102\n",
              "7       union   5,901\n",
              "8  parliament   5,693\n",
              "9        like   5,545"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxTzgEZwfgi8",
        "outputId": "8467d34f-d651-4558-c380-ed170f075bb9"
      },
      "source": [
        "# word from the given list doesn’t go with the others\n",
        "\n",
        "unmatced_word= model.doesnt_match(words)\n",
        "print(\"The word that doesn't match is:\", unmatced_word)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word that doesn't match is: fellows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPIPBK08fgmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1599a749-1334-4737-84a3-a7275d9f4a76"
      },
      "source": [
        "#Find the top-N most similar words. Positive words contribute positively towards the similarity, negative words negatively.\n",
        "\n",
        "sims = model.most_similar(positive=['mrs', 'king'], negative=['mr'], topn=3)\n",
        "print(sims)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('emulating', 0.7795901298522949), ('spaniards', 0.7748528122901917), ('vertreter', 0.7672560214996338)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nBi75pgwtjj"
      },
      "source": [
        "\n",
        "\n",
        "> SAVE THE MODEL\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSbSsx8pwzMS",
        "outputId": "4e3a0026-294c-4926-a328-7f8174e01a2a"
      },
      "source": [
        "model.save(\"word2vec.model\")\n",
        "print(\"Model saved!\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09:43:41 : saving Word2Vec object under word2vec.model, separately None\n",
            "09:43:41 : not storing attribute vectors_norm\n",
            "09:43:41 : not storing attribute cum_table\n",
            "09:43:42 : saved word2vec.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved!\n"
          ]
        }
      ]
    }
  ]
}